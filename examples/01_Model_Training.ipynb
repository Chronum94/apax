{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "In this tutorial we are going to train a model from scratch on a molecular dataset from the MD17 collection.\n",
    "Start by creating a project folder and downloading the dataset.\n",
    "\n",
    "## Acquiring a dataset\n",
    "\n",
    "You can obtain the benzene dataset with DFT labels either by running the following command or manually from this [link](http://www.quantum-machine.org/gdml/data/xyz/benzene2018_dft.zip). Apax uses ASE to read in datasets, so make sure to convert your own data into an ASE readable format (extxyz, traj etc). Be carefull the downloaded dataset has to be modified like in the `apax.untils.dataset.mop_md17` function in order to be readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from apax.utils.datasets import download_md17_benzene_DFT, mod_md17\n",
    "\n",
    "data_path = Path(\"project\")\n",
    "\n",
    "file_path = download_md17_benzene_DFT(data_path)\n",
    "file_path = mod_md17(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration files\n",
    "\n",
    "Next, we require a configuration file that specifies the model and training parameters.\n",
    "In order to get users quickly up and running, our command line interface provides an easy way to generate input templates.\n",
    "The provided templates come in in two levels of verbosity: minimal and full.\n",
    "In the following we are going to use a minimal input file. To see a complete list and explanation of all parameters, consult the documentation page LINK.\n",
    "For more information on the CLI,  simply run `apax -h`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apax -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command create a minimal configuration file in the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apax template train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the resulting `config.yaml` file in an editor of your choice and make sure to fill in the data path field with the name of the data set you just downloaded.\n",
    "For the purposes of this tutorial we will train on 1000 data points and validate the model on 200 more during the training. Further, the units of the labels have to be specified. Random splitting is done by apax but it is also possible to input a pre-splitted training and validation dataset\n",
    "\n",
    "The filled in configuration file should look similar to this one.\n",
    "\n",
    "```yaml\n",
    "epoch: 1000\n",
    "data:\n",
    "    data_path: md17.extexyz\n",
    "    epochs: 1000\n",
    "    n_train: 1000\n",
    "    energy_unit: kcal/mol\n",
    "    pos_unit: Ang\n",
    "    ....\n",
    "```\n",
    "\n",
    "It also can be modefied with the utils function `mod_config` provided by Apax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apax.utils.helpers import mod_config\n",
    "import yaml\n",
    "\n",
    "\n",
    "config_path = Path(\"config.yaml\")\n",
    "\n",
    "config_updates = {\n",
    "    \"n_epochs\": 10,\n",
    "    \"data\": {\n",
    "        \"experiment\": \"benzene_dft_cli\",\n",
    "        \"directory\": \"project/models\",\n",
    "        \"data_path\": str(file_path),\n",
    "        \"energy_unit\": \"kcal/mol\",\n",
    "        \"pos_unit\": \"Ang\",\n",
    "    }\n",
    "}\n",
    "config_dict = mod_config(config_path, config_updates)\n",
    "\n",
    "with open(\"config.yaml\", \"w\") as conf:\n",
    "    yaml.dump(config_dict, conf, default_flow_style=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In order to check whether the a configuration file is valid, we provide the `validate` command. This is especially convenient when submitting training runs on a compute cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apax validate train config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration files are validated using Pydantic and the errors provided by the `validate` command give precise instructions on how to fix the input file.\n",
    "For example, changing `epochs` to `-1000`, validate will give the following feedback to the user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_updates = {\n",
    "    \"n_epochs\": -1000,\n",
    "}\n",
    "config_dict = mod_config(config_path, config_updates)\n",
    "\n",
    "with open(\"error_config.yaml\", \"w\") as conf:\n",
    "    yaml.dump(config_dict, conf, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apax validate train error_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Model training can be started by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apax train config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "During training, apax displays a progress bar to keep track of the validation loss.\n",
    "This progress bar is optional however and can be turned off in the config. LINK\n",
    "The default configuration writes training metrics to a CSV file, but TensorBoard is also supported.\n",
    "One can specify which to use by adding the following section to the input file:\n",
    "\n",
    "```yaml\n",
    "callbacks:\n",
    "    - CSV\n",
    "```\n",
    "\n",
    "If training is interrupted for any reason, re-running the above `train` command will resume training from the latest checkpoint.\n",
    "\n",
    "Furthermore, an Apax trianing can easily be started within a scriped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apax.train.run import run\n",
    "\n",
    "config_path = Path(\"config.yaml\")\n",
    "\n",
    "config_updates = {\n",
    "    \"n_epochs\": 100,\n",
    "    \"data\": {\n",
    "        \"experiment\": \"benzene_dft_script\",\n",
    "        \"directory\": \"project/models\",\n",
    "        \"data_path\": str(file_path),\n",
    "        \"energy_unit\": \"kcal/mol\",\n",
    "        \"pos_unit\": \"Ang\",\n",
    "    }\n",
    "}\n",
    "\n",
    "config_dict = mod_config(config_path, config_updates)\n",
    "\n",
    "run(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path = \"project/models/benzene_dft_script/log.csv\"\n",
    "\n",
    "keys = [\"energy_mae\", \"forces_mse\", \"forces_mae\", \"loss\"]\n",
    "data_dict = {}\n",
    "\n",
    "with open(path, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Extract the headers (keys) from the first row\n",
    "    headers = next(reader)\n",
    "\n",
    "    # Initialize empty lists for each key\n",
    "    for header in headers:\n",
    "        data_dict[header] = []\n",
    "\n",
    "    # Read the rest of the rows and append values to the corresponding key\n",
    "    for row in reader:\n",
    "        for idx, value in enumerate(row):\n",
    "            key = headers[idx]\n",
    "            data_dict[key].append(float(value))\n",
    "\n",
    "for key in keys:\n",
    "    fig, axes = plt.subplots(1, 2, sharey=True, sharex=True, figsize=(18, 4))\n",
    "\n",
    "    val = np.array(data_dict[f\"val_{key}\"])\n",
    "    train = np.array(data_dict[f\"train_{key}\"])\n",
    "    epoch = np.array(data_dict[\"epoch\"])\n",
    "\n",
    "    axes[0].plot(epoch, val)\n",
    "    axes[1].plot(epoch, train)\n",
    "\n",
    "    axes[0].set_ylabel(f\"val_{key}\")\n",
    "    axes[0].set_xlabel(r\"epoch\")\n",
    "    axes[1].set_ylabel(f\"train_{key}\")\n",
    "    axes[1].set_xlabel(r\"epoch\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "After the training is completed and we are satisfied with our choice of hyperparameters and vadliation loss, we can evaluate the model on the test set.\n",
    "We provide a separate command for test set evaluation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apax evaluate config_minimal.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "TODO pretty print results to the terminal\n",
    "\n",
    "Congratulations, you have successfully trained and evaluated your first apax model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Closer Look At Training Parameters\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove all the created files and clean up yor working directory run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r project config.yaml error_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apax311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
