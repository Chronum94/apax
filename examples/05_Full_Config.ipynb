{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO add all options to description of the parameter example Ã¯solated_atoms_shift and per_element_regression_shift\n",
    "\n",
    "- **n_epochs**: int (required)\n",
    "\n",
    "  >Number of training epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **seed**: int (default = 1)\n",
    "  \n",
    "    >Seed for initializing random numbers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **patience**: int (optional)\n",
    "\n",
    "  >Number of epochs without improvement before training termination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **n_models**: int (default = 1)\n",
    "\n",
    "  >Number of models trained simultaneously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **n_jitted_steps**: int (default = 1)\n",
    "\n",
    "  >Number of train batches in a compiled loop. Can speed up for small batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Data**\n",
    "  - directory: str (default = \"/models\")\n",
    "\n",
    "    >Path to directory where training results and checkpoints are written.\n",
    "\n",
    "\n",
    "  - experiment: str (default = \"apax\")\n",
    "\n",
    "    >Model name distinguishing from others in directory.  \n",
    "\n",
    "\n",
    "  - data_path: str (required if train_ and val_data_path is not specified)\n",
    "\n",
    "    >Path to single dataset file.\n",
    "    \n",
    "\n",
    "  - train_data_path: str (required if data_path is not specified)\n",
    "    >Path to training dataset.\n",
    "\n",
    "  - val_data_path: str (required if data_path is not specified)\n",
    "    >Path to validation dataset.\n",
    "\n",
    "  - test_data_path: str (optional)\n",
    "    >Path to test dataset.\n",
    "\n",
    "  - n_train: int (default = 1000)\n",
    "    >Number of training data points.\n",
    "    \n",
    "  - n_valid: int (default = 100)\n",
    "    >Number of validation data points.\n",
    "    \n",
    "  - batch_size: int (default = 32)\n",
    "    >Number of training examples evaluated at once.\n",
    "    \n",
    "  - valid_batch_size: int (default = 100)\n",
    "    >Number of validation examples evaluated at once.\n",
    "    \n",
    "  - shift_method: str (default = \"per_element_regression_shift\")\n",
    "    >Method for shifting.\n",
    "    \n",
    "  - shift_options: dict (default = {\"energy_regularization\": 1.0})\n",
    "    >Regularization magnitude for energy regression. #TODO fill in the other options\n",
    "    \n",
    "  - shuffle_buffer_size: int (default = 1000)\n",
    "    >Size of `tf.data` shuffle buffer.\n",
    "    \n",
    "  - pos_unit: str (default = \"Ang\")\n",
    "    >Positional unit.\n",
    "    \n",
    "  - energy_unit: str (default = \"eV\")\n",
    "    >Energy unit.\n",
    "    \n",
    "  - additional_properties_info: dict (optional)\n",
    "    >Dictionary of property name, shape pairs.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Model**\n",
    "  - n_basis: int (default = 7)\n",
    "    >Number of Gaussian basis functions.\n",
    "\n",
    "  - n_radial: int (default = 5)\n",
    "    >Number of contracted basis functions.\n",
    "\n",
    "  - nn: list of int (default = [512, 512])\n",
    "    >Hidden layers and units.\n",
    "\n",
    "  - r_max: float (default = 6.0)\n",
    "    >Maximum position of first basis function's mean in angstrom.\n",
    "\n",
    "  - r_min: float (default = 0.5)\n",
    "    >Descriptor cutoff radius in angstrom.\n",
    "\n",
    "  - use_zbl: bool (default = false)\n",
    "    >Use emperical Ziegler-Biersack-Littmark potential.\n",
    "\n",
    "  - b_init: str (default = \"normal\")\n",
    "    >Initialization scheme for biases.  #TODO fill in the other options\n",
    "\n",
    "  - descriptor_dtype: str (default = \"fp64\")\n",
    "    >Descriptor data type.\n",
    "\n",
    "  - readout_dtype: str (default = \"fp32\")\n",
    "    >Readout data type.\n",
    "\n",
    "  - scale_shift_dtype: str (default = \"fp32\")\n",
    "    >Scale/Shift data type.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Loss**\n",
    "  - loss_type: str (default = \"structures\")\n",
    "    >Weighting scheme for atomic contributions.  #TODO fill in the other options\n",
    "\n",
    "  - name: str (default = \"energy\")\n",
    "    >Quantity keyword.\n",
    "\n",
    "  - weight: float (default = 1.0)\n",
    "    >Weighting factor in loss function.\n",
    "\n",
    "  - name: str (default = \"forces\")\n",
    "    >Quantity keyword.\n",
    "\n",
    "  - weight: float (default = 4.0)\n",
    "    >Weighting factor in loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Metrics**\n",
    "  - name: str (default = \"energy\")\n",
    "    >Quantity keyword.\n",
    "    \n",
    "  - reductions:\n",
    "    >List of reductions on target-prediction differences.\n",
    "    \n",
    "  - name: str (default = \"forces\")\n",
    "    >Quantity keyword.\n",
    "    \n",
    "  - reductions: list of str (default = [mae, mse])\n",
    "    >Reductions on target-prediction differences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Optimizer**\n",
    "  - opt_name: str (default = \"adam\")\n",
    "    >Optimizer name.  #TODO fill in the other options\n",
    "    \n",
    "  - opt_kwargs: dict (if optimizer requires)\n",
    "    >Optimizer keyword arguments.\n",
    "    \n",
    "  - emb_lr: float (default = 0.03)\n",
    "    >Learning rate for elemental embedding contraction coefficients.\n",
    "    \n",
    "  - nn_lr: float (default = 0.03)\n",
    "    >Learning rate for neural network parameters.\n",
    "    \n",
    "  - scale_lr: float (default = 0.001)\n",
    "    >Learning rate for elemental output scaling factors.\n",
    "    \n",
    "  - shift_lr: float (default = 0.05)\n",
    "    >Learning rate for elemental output shifts.\n",
    "    \n",
    "  - zbl_lr: float (default = 0.001)\n",
    "    >Learning rate for Zero-Body-Loss.\n",
    "    \n",
    "  - transition_begin: int (default = 0)\n",
    "    >Training steps before linear learning rate schedule.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Callbacks**\n",
    "  - name: str (default = \"csv\")  \n",
    "    >Callback name.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Progress Bar**\n",
    "  - disable_epoch_pbar: bool (default = false)\n",
    "    >Disable epoch progress bar.\n",
    "\n",
    "  - disable_nl_pbar: bool (default = false)\n",
    "    >Disable NL precomputation progress bar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Checkpoints**\n",
    "  - ckpt_interval: int (default = 1)\n",
    "    >Epochs between checkpoints.\n",
    "    \n",
    "  - base_model_checkpoint: (optional)\n",
    "    >Path to pre-trained model checkpoint.\n",
    "    \n",
    "  - reset_layers: (optional)\n",
    "    >List of layers to reinitialize parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameter                  | Default Value                  | Description                                                                 |\n",
    "|----------------------------|--------------------------------|-----------------------------------------------------------------------------|\n",
    "| **n_epochs**               | `<NUMBER OF EPOCHS>`           | Number of training epochs.                                                  |\n",
    "| **seed**                   | 1                              | Seed for initializing random numbers.                                       |\n",
    "| **patience**               | None                           | Number of epochs without improvement before training termination.          |\n",
    "| **n_models**               | 1                              | Number of models trained simultaneously.                                    |\n",
    "| **n_jitted_steps**         | 1                              | Number of train batches in a compiled loop. Can speed up for small batches. |\n",
    "| **Data**                   |                                |                                                                             |\n",
    "| directory                  | models/                        | Path to directory where training results and checkpoints are written.      |\n",
    "| experiment                 | apax                           | Model name distinguishing from others in directory.                         |\n",
    "| data_path                  | `<PATH>`                       | Path to single dataset file.                                               |\n",
    "| train_data_path            | `<PATH>`                       | Path to training dataset.                                                   |\n",
    "| val_data_path              | `<PATH>`                       | Path to validation dataset.                                                 |\n",
    "| test_data_path             | `<PATH>`                       | Path to test dataset.                                                       |\n",
    "| n_train                    | 1000                           | Number of training data points.                                             |\n",
    "| n_valid                    | 100                            | Number of validation data points.                                           |\n",
    "| batch_size                 | 32                             | Number of training examples evaluated at once.                             |\n",
    "| valid_batch_size           | 100                            | Number of validation examples evaluated at once.                           |\n",
    "| shift_method               | \"per_element_regression_shift\" | Method for shifting.                                                        |\n",
    "| shift_options              | energy_regularization: 1.0     | Regularization magnitude for energy regression.                             |\n",
    "| shuffle_buffer_size        | 1000                           | Size of `tf.data` shuffle buffer.                                           |\n",
    "| pos_unit                   | Ang                            | Positional unit.                                                            |\n",
    "| energy_unit                | eV                             | Energy unit.                                                                |\n",
    "| additional_properties_info |                                | Dictionary of property name, shape pairs.                                   |\n",
    "| **Model**                  |                                |                                                                             |\n",
    "| n_basis                    | 7                              | Number of Gaussian basis functions.                                         |\n",
    "| n_radial                   | 5                              | Number of contracted basis functions.                                      |\n",
    "| nn                         | [512, 512]                     | Hidden layers and units.                                                    |\n",
    "| r_max                      | 6.0                            | Maximum position of first basis function's mean.                           |\n",
    "| r_min                      | 0.5                            | Descriptor cutoff radius.                                                   |\n",
    "| use_zbl                    | false                          | Use Zero-Body-Loss.                                                         |\n",
    "| b_init                     | normal                         | Initialization scheme for biases.                                           |\n",
    "| descriptor_dtype           | fp64                           | Descriptor data type.                                                       |\n",
    "| readout_dtype              | fp32                           | Readout data type.                                                          |\n",
    "| scale_shift_dtype          | fp32                           | Scale/Shift data type.                                                      |\n",
    "| **Loss**                   |                                |                                                                             |\n",
    "| loss_type                  | structures                     | Weighting scheme for atomic contributions.                                 |\n",
    "| name                       | energy                         | Quantity keyword.                                                           |\n",
    "| weight                     | 1.0                            | Weighting factor in loss function.                                          |\n",
    "| name                       | forces                         | Quantity keyword.                                                           |\n",
    "| weight                     | 4.0                            | Weighting factor in loss function.                                          |\n",
    "| **Metrics**                |                                |                                                                             |\n",
    "| name                       | energy                         | Quantity keyword.                                                           |\n",
    "| reductions                 |                                | List of reductions on target-prediction differences.                        |\n",
    "| name                       | forces                         | Quantity keyword.                                                           |\n",
    "| reductions                 | mae, mse                       | Reductions on target-prediction differences.                               |\n",
    "| **Optimizer**              |                                |                                                                             |\n",
    "| opt_name                   | adam                           | Optimizer name.                                                             |\n",
    "| opt_kwargs                 | {}                             | Optimizer keyword arguments.                                                |\n",
    "| emb_lr                     | 0.03                           | Learning rate for elemental embedding contraction coefficients.            |\n",
    "| nn_lr                      | 0.03                           | Learning rate for neural network parameters.                                |\n",
    "| scale_lr                   | 0.001                          | Learning rate for elemental output scaling factors.                        |\n",
    "| shift_lr                   | 0.05                           | Learning rate for elemental output shifts.                                  |\n",
    "| zbl_lr                     | 0.001                          | Learning rate for Zero-Body-Loss.                                           |\n",
    "| transition_begin           | 0                              | Training steps before linear learning rate schedule.                        |\n",
    "| **Callbacks**              |                                |                                                                             |\n",
    "| name                       | csv                            | Callback name.                                                              |\n",
    "| **Progress Bar**           |                                |                                                                             |\n",
    "| disable_epoch_pbar         | false                          | Disable epoch progress bar.                                                 |\n",
    "| disable_nl_pbar            | false                          | Disable NL precomputation progress bar.                                     |\n",
    "| **Checkpoints**            |                                |                                                                             |\n",
    "| ckpt_interval              | 1                              | Epochs between checkpoints.                                                 |\n",
    "| base_model_checkpoint     | null                           | Path to pre-trained model checkpoint.                                       |\n",
    "| reset_layers               | []                             | List of layers to reinitialize parameters.                                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Configuration File\n",
    " \n",
    "```yaml\n",
    "n_epochs: <NUMBER OF EPOCHS>  # Number of training epochs.\n",
    "seed: 1                       # Seed for initialising random numbers\n",
    "patience: None                # Number of epochs without improvement before trainings gets terminated.\n",
    "n_models: 1                   # Number of models to be trained at once.\n",
    "n_jitted_steps: 1             # Number of train batches to be processed in a compiled loop. \n",
    "                              # Can yield singificant speedups for small structures or small batch sizes.\n",
    "\n",
    "data:\n",
    "  directory: models/          # Path to the directory where the training results and checkpoints will be written.\n",
    "  experiment: apax            # Name of  the model. Distinguishes it from the other models trained in the same `directory`.\n",
    "  data_path: <PATH>           # Path to a single dataset file. Set either this or `val_data_path` and `train_data_path`.\n",
    "  train_data_path: <PATH>     # Path to a training dataset. Set this and `val_data_path` if your data comes pre-split.\n",
    "  val_data_path: <PATH>       # Path to a validation dataset. Set this and `train_data_path` if your data comes pre-split.\n",
    "  test_data_path: <PATH>      # Path to a test dataset. Set this, `train_data_path` and `val_data_path` if your data comes pre-split.\n",
    "\n",
    "  n_train: 1000               # Number of training datapoints from `data_path`.\n",
    "  n_valid: 100                # Number of validation datapoints from `data_path`.\n",
    "\n",
    "  batch_size: 32              # Number of training examples to be evaluated at once.\n",
    "  valid_batch_size: 100       # Number of validation examples to be evaluated at once.\n",
    "\n",
    "  shift_method: \"per_element_regression_shift\"\n",
    "  shift_options:\n",
    "    energy_regularisation: 1.0    # Magnitude of the regularization in the per-element energy regression.\n",
    "  shuffle_buffer_size: 1000       # Size of the `tf.data` shuffle buffer.\n",
    "\n",
    "  pos_unit: Ang\n",
    "  energy_unit: eV\n",
    "\n",
    "  additional_properties_info:     # Dict of property name, shape (ragged or fixed) pairs\n",
    "\n",
    "model:\n",
    "  n_basis: 7                  # Number of uncontracted gaussian basis functions.\n",
    "  n_radial: 5                 # Number of contracted basis functions.\n",
    "  nn: [512, 512]              # Number of hidden layers and units in those layers.\n",
    "\n",
    "  r_max: 6.0                  # Position of the first uncontracted basis function's mean.\n",
    "  r_min: 0.5                  # Cutoff radius of the descriptor.\n",
    "\n",
    "  use_zbl: false              # \n",
    "\n",
    "  b_init: normal              # Initialization scheme for the neural network biases. Either `normal` or `zeros`.\n",
    "  descriptor_dtype: fp64\n",
    "  readout_dtype: fp32\n",
    "  scale_shift_dtype: fp32\n",
    "\n",
    "loss:\n",
    "- loss_type: structures       # Weighting scheme for atomic contributions.\n",
    "                              # See the MLIP package for reference 10.1088/2632-2153/abc9fe for details\n",
    "  name: energy                # Keyword of the quantity e.g `energy`.\n",
    "  weight: 1.0                 # Weighting factor in the overall loss function.\n",
    "- loss_type: structures\n",
    "  name: forces\n",
    "  weight: 4.0\n",
    "\n",
    "metrics:\n",
    "- name: energy                # Keyword of the quantity e.g `energy`.\n",
    "  reductions:                 # List of reductions performed on the difference between target and predictions.\n",
    "                              # Can be mae, mse, rmse for energies and forces. For forces it is also possible to use `angle`.\n",
    "  - mae\n",
    "- name: forces\n",
    "  reductions:\n",
    "  - mae\n",
    "  - mse\n",
    "\n",
    "optimizer:\n",
    "  opt_name: adam            # Name of the optimizer. Can be any `optax` optimizer.\n",
    "  opt_kwargs: {}            # Optimizer keyword arguments. Passed to the `optax` optimizer.\n",
    "  emb_lr: 0.03              # Learning rate of the elemental embedding contraction coefficients.\n",
    "  nn_lr: 0.03               # Learning rate of the neural network parameters.\n",
    "  scale_lr: 0.001           # Learning rate of the elemental output scaling factors.\n",
    "  shift_lr: 0.05            # Learning rate of the elemental output shifts.\n",
    "  zbl_lr: 0.001             # \n",
    "  transition_begin: 0       # Number of training steps (not epochs) before the start of the linear learning rate schedule.\n",
    "\n",
    "callbacks:\n",
    "- name: csv                 # Keyword of the callback used. Currently we implement \"csv\" and \"tensorboard\".\n",
    "\n",
    "progress_bar:\n",
    "  disable_epoch_pbar: false   # Set to True to disable the epoch progress bar.\n",
    "  disable_nl_pbar: false      # Set to True to disable the NL precomputation progress bar.\n",
    "\n",
    "\n",
    "checkpoints:\n",
    "  ckpt_interval: 1                # Number of epochs between checkpoints.\n",
    "  \n",
    "                                  # The options below are used for transfer learning\n",
    "  base_model_checkpoint: null     # Path to the folder containing a pre-trained model ckpt.\n",
    "  reset_layers: []                # List of layer names for which the parameters will be reinitialized.\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
